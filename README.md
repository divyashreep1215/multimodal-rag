# multimodal-rag
A Multimodal RAG system that processes text and images to generate context-aware answers. It uses document chunking, embeddings, and FAISS for semantic search, and integrates an LLM for accurate response generation.
# ğŸ“š Multimodal RAG System

A production-ready Multimodal Retrieval-Augmented Generation (RAG) system built using Streamlit, FAISS, Sentence Transformers, and Groq LLM.

This application allows users to upload documents (PDF) and ask context-aware questions using vector search and LLM generation.

---

## ğŸš€ Features

- ğŸ“„ PDF Document Upload
- ğŸ” Text Chunking with Overlap
- ğŸ§  Sentence-Transformer Embeddings
- ğŸ“¦ FAISS Vector Database
- ğŸ¯ Cross-Encoder Reranking
- ğŸ¤– Groq LLM for Context-Aware Answers
- ğŸŒ Streamlit Web Interface
- â˜ï¸ Deployable on Streamlit Cloud

---

## ğŸ—ï¸ Project Structure

multimodal_rag/

â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
â”‚
â””â”€â”€ rag/
â”œâ”€â”€ init.py
â”œâ”€â”€ embeddings.py
â”œâ”€â”€ retriever.py
â”œâ”€â”€ reranker.py
â”œâ”€â”€ chunking.py
â”œâ”€â”€ llm.py
â”œâ”€â”€ vision.py
